{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a54e852-8dc8-4fe6-8166-a47b750fddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bae19029-219d-4206-974b-1d8ed5be0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from file for 5DL1 promoter \n",
    "data=np.load(\"science_data_lacUD5.npy\")\n",
    "\n",
    "# Extract x and y data\n",
    "x_data = data[:, 0]\n",
    "y_data = data[:, 1]\n",
    "\n",
    "# Get unique x values and their corresponding indices\n",
    "unique_x, unique_indices = np.unique(x_data, return_index=True)\n",
    "\n",
    "# Extract unique y values based on unique indices\n",
    "unique_y = y_data[unique_indices]\n",
    "\n",
    "# Create unique data array with x and y values\n",
    "unique_data = np.column_stack((unique_x, unique_y))\n",
    "\n",
    "# Convert mean and variance data to torch tensors\n",
    "mean_data = torch.from_numpy(unique_data[:, 0]).double()\n",
    "var_data = mean_data * torch.from_numpy(unique_data[:, 1]).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a27dc876-ff80-4fc1-904b-62ee66bcf950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stoichiometric matrix defining the effect of each reaction on the system\n",
    "stoic_matrix = torch.tensor([[2.0, 0.0],    # Reaction 1: Promoter state goes from -1 to +1\n",
    "                             [0.0, 1.0],    # Reaction 2: mRNA is produced\n",
    "                             [-2.0, 0.0],   # Reaction 3: Promoter state goes from +1 to -1\n",
    "                             [0.0, -1.0]])  # Reaction 4: Degradation of mRNA\n",
    "\n",
    "def state_jump(reaction_index, stoic_matrix):\n",
    "    \"\"\"\n",
    "    Calculate state jump vector based on the selected reaction index and stoichiometry matrix, where, \n",
    "    state vector -> state vector + state jump vector.\n",
    "\n",
    "    Arguments:\n",
    "        reaction_index: Selected reaction index\n",
    "        stoic_matrix: Stoichiometry matrix\n",
    "\n",
    "    Returns:\n",
    "        State jump vector\n",
    "    \"\"\" \n",
    "    return torch.sum(stoic_matrix * (torch.exp(-b_inv * (reaction_index - torch.arange(stoic_matrix.shape[0]))**2)).view(-1, 1), dim=0)\n",
    "\n",
    "def reaction_selection(breaks, random_num):\n",
    "    \"\"\"\n",
    "    Select reaction based on the transition points and a random number. Transition points are \n",
    "    given by the ratio of cumulative sum of rates and the total rate.\n",
    "\n",
    "    Arguments:\n",
    "        breaks: Transition points between [0,1]\n",
    "        random_num: Random number in [0,1]\n",
    "\n",
    "    Returns:\n",
    "        Index of the next reaction\n",
    "    \"\"\"\n",
    "    return torch.sum(torch.sigmoid(a_inv * (random_num - breaks)))\n",
    "\n",
    "def gillespie_simulation(poff_values, r, g):\n",
    "    \"\"\"\n",
    "    Perform differentiable Gillespie simulation for a 2-state promoter model.\n",
    "    \n",
    "    Arguments:\n",
    "        poff_values: Array of probabilities for promoter to be in OFF state. poff=koff/(kon+koff)\n",
    "        r: Rate of mRNA production.\n",
    "        g: Rate of mRNA degradation.\n",
    "        \n",
    "    Returns:\n",
    "        mean_final_states: Mean of the mRNA levels at the end of the simulation.\n",
    "        variances: Variance of the mRNA levels at the end of the simulation.\n",
    "    \"\"\"\n",
    "    # Initialize random seed for reproducibility\n",
    "    random_seed = torch.randint(1, 10000000, (1,))\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    mean_final_states = torch.empty(len(unique_data))\n",
    "    variances = torch.empty(len(unique_data))\n",
    "    \n",
    "    for n in range(len(unique_data)):\n",
    "        poff = poff_values[n].unsqueeze(0)\n",
    "        \n",
    "        final_states = 0.0\n",
    "        final_states_squared = 0.0\n",
    "\n",
    "        for j in range(num_simulations):\n",
    "            # Initial 'levels':\n",
    "            # The first component of 'levels' is the promoter state, initialized to -1\n",
    "            # The second component of 'levels' is the mRNA level, initialized to 0.\n",
    "            levels = torch.stack([torch.tensor(-1.0), torch.tensor(0.0)])\n",
    "            current_time = 0.0\n",
    "\n",
    "            while current_time < sim_time:\n",
    "                # Calculate reaction propensities\n",
    "                propensities = torch.stack([(1/poff-1.0) * torch.sigmoid(-c*levels[0]), \n",
    "                                            r * torch.sigmoid(-c*levels[0]), \n",
    "                                            torch.tensor([1.0]) * torch.sigmoid(c * levels[0]), \n",
    "                                            g * levels[1]])\n",
    "                propensities = torch.relu(propensities)\n",
    "\n",
    "                # Sum of all propensities\n",
    "                total_propensity = propensities.sum()\n",
    "\n",
    "                # Time until next reaction\n",
    "                dt = -torch.log(torch.rand(1)) / total_propensity\n",
    "                current_time += dt.item()\n",
    "\n",
    "                if current_time >= sim_time:\n",
    "                    break\n",
    "\n",
    "                # Determine which reaction occurs and update the system state\n",
    "                breaks = (propensities[:-1] / total_propensity).cumsum(dim=0)\n",
    "                reaction_index = reaction_selection(breaks, torch.rand(1))\n",
    "                levels = levels + state_jump(reaction_index, stoic_matrix)\n",
    "                levels[1] = torch.relu(levels[1])  # Ensure non-negative values for the mRNA number\n",
    "\n",
    "            # Accumulate mRNA level and its square\n",
    "            final_states += levels[1]\n",
    "            final_states_squared += levels[1] ** 2\n",
    "\n",
    "        # Calculate mean and variance of mRNA levels\n",
    "        mean_final_state = final_states / num_simulations\n",
    "        variance = final_states_squared / num_simulations - mean_final_state ** 2\n",
    "        \n",
    "        mean_final_states[n] = mean_final_state\n",
    "        variances[n] = variance\n",
    "\n",
    "    return mean_final_states, variances\n",
    "\n",
    "def loss_function(mean_final_states, variances):\n",
    "    \"\"\"\n",
    "    Loss function that calculates the mean squared error of the simulation results against data.\n",
    "\n",
    "    Arguments:\n",
    "        mean_final_states: Mean of the mRNA levels at the end of the simulation.\n",
    "        variances: Variance of the mRNA levels at the end of the simulation.\n",
    "        \n",
    "    Returns:\n",
    "        Loss value\n",
    "    \"\"\"\n",
    "    return torch.mean((mean_final_states - mean_data)**2 + (variances**0.5 - var_data**0.5)**2)\n",
    "\n",
    "# Define a function to write data to a file\n",
    "def write_to_file(filename, *args):\n",
    "    with open(filename, 'a') as file:\n",
    "        file.write(' '.join(map(str, args)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1d0f1c-841b-4b5e-83f2-bc61d3ea6494",
   "metadata": {},
   "source": [
    "## gradient descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e8bdbae-4a19-4e8a-87b9-7ceee99810ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss = 30.2842\n",
      "Epoch 10: Loss = 7.3902\n",
      "Epoch 20: Loss = 7.4203\n",
      "Epoch 30: Loss = 9.4783\n",
      "Epoch 40: Loss = 6.8227\n",
      "Epoch 50: Loss = 6.8458\n",
      "Epoch 60: Loss = 6.5665\n",
      "Epoch 70: Loss = 6.8031\n",
      "Epoch 80: Loss = 9.4715\n",
      "Epoch 90: Loss = 8.2573\n",
      "Epoch 100: Loss = 6.6775\n",
      "Epoch 110: Loss = 7.0401\n",
      "Epoch 120: Loss = 7.4055\n",
      "Epoch 130: Loss = 6.3643\n",
      "Epoch 140: Loss = 7.3031\n",
      "Epoch 150: Loss = 6.3296\n",
      "Epoch 160: Loss = 7.8660\n",
      "Epoch 170: Loss = 5.2484\n",
      "Epoch 180: Loss = 8.6747\n",
      "Epoch 190: Loss = 8.4150\n",
      "Epoch 200: Loss = 7.9563\n",
      "Epoch 210: Loss = 5.6545\n",
      "Epoch 220: Loss = 5.4568\n",
      "Epoch 230: Loss = 5.0684\n",
      "Epoch 240: Loss = 5.4674\n",
      "Epoch 250: Loss = 5.0441\n",
      "Epoch 260: Loss = 4.6212\n",
      "Epoch 270: Loss = 6.2036\n",
      "Epoch 280: Loss = 8.8834\n",
      "Epoch 290: Loss = 6.0449\n",
      "Epoch 300: Loss = 5.4475\n",
      "Epoch 310: Loss = 5.8853\n",
      "Epoch 320: Loss = 5.1000\n",
      "Epoch 330: Loss = 7.5838\n",
      "Epoch 340: Loss = 9.0628\n",
      "Epoch 350: Loss = 5.3896\n",
      "Epoch 360: Loss = 5.1916\n",
      "Epoch 370: Loss = 5.0366\n",
      "Epoch 380: Loss = 5.5556\n",
      "Epoch 390: Loss = 5.5904\n",
      "Epoch 400: Loss = 5.7140\n",
      "Epoch 410: Loss = 5.7225\n",
      "Epoch 420: Loss = 5.2400\n",
      "Epoch 430: Loss = 5.7239\n",
      "Epoch 440: Loss = 6.6425\n",
      "Epoch 450: Loss = 6.0888\n",
      "Epoch 460: Loss = 5.7942\n",
      "Epoch 470: Loss = 6.0893\n",
      "Epoch 480: Loss = 10.9331\n",
      "Epoch 490: Loss = 6.0349\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility \n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define simulation hyperparameters\n",
    "num_iterations = 500\n",
    "num_simulations = 200\n",
    "sim_time = 0.2\n",
    "a_inv = 200.0\n",
    "b_inv =20.0\n",
    "c = 20.0\n",
    "\n",
    "# Initialize parameters with random values\n",
    "poff_values = torch.nn.Parameter(torch.linspace(0.03, 0.97, len(unique_data)))\n",
    "r = torch.nn.Parameter((1e+2) * torch.rand(1))\n",
    "g = torch.nn.Parameter((1e+1) * torch.rand(1))\n",
    "\n",
    "# Define the Adam optimizer and include all parameters that require gradients\n",
    "optimizer = optim.Adam([poff_values, r, g], lr=0.1)\n",
    "\n",
    "# Define filenames for saving results\n",
    "filename1 = \"learning_science_lacUD5_poff_500.txt\"\n",
    "if os.path.exists(filename1):\n",
    "    os.remove(filename1)   \n",
    "filename2 = \"learning_science_lacUD5_500.txt\"\n",
    "if os.path.exists(filename2):\n",
    "    os.remove(filename2)\n",
    "\n",
    "# Main optimization loop\n",
    "for iteration in range(num_iterations):\n",
    "    \n",
    "    # Forward differentiable Gillespie simulation\n",
    "    mean_final_states, variances = gillespie_simulation(poff_values, r, g)\n",
    "    \n",
    "    # Compute the loss for the current iteration\n",
    "    loss = loss_function(mean_final_states, variances)\n",
    "\n",
    "    # Zero the gradients to prepare for backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the gradient of the loss with respect to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients to prevent exploding gradients problem\n",
    "    torch.nn.utils.clip_grad_norm_([poff_values, r, g], max_norm=1.0)\n",
    "\n",
    "    # Update the parameters using the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    # Clamp r and g to ensure they are within valid range\n",
    "    r.data = torch.clamp(r.data, min=1.0)\n",
    "    g.data = torch.clamp(g.data, min=1.0, max=r.item())\n",
    "    poff_values.data = torch.clamp(poff_values, min=0.01, max=0.98)\n",
    "    poff_values.data, _ = torch.sort(poff_values.data)\n",
    "\n",
    "    # Save the values of the parameters after each iteration\n",
    "    if iteration % 1 == 0:\n",
    "        write_to_file(filename2, iteration, r.item(), g.item(), r.item() / g.item(), loss.item())\n",
    "        write_to_file(filename1, poff_values.tolist(), loss.item())\n",
    "\n",
    "    if iteration % 10 == 0:\n",
    "        print(f\"Epoch {iteration}: Loss = {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b7ab11-2934-4277-8ae5-07593169f7ab",
   "metadata": {},
   "source": [
    "### Extract learned parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8e23a2f-5ab3-4182-92ba-4056d165d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the row index with minimum loss value. \n",
    "data=np.loadtxt(\"learning_science_lacUD5_500.txt\")\n",
    "row_index = np.argmin(data[:, -1])\n",
    "r=data[row_index,1]\n",
    "g=data[row_index, 2]\n",
    "\n",
    "# Path to poff_values\n",
    "file_path = 'learning_science_lacUD5_poff_500.txt'\n",
    "\n",
    "# Initialize an empty list to store rows\n",
    "poff_values = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove the trailing number by splitting at the last space and taking the first part\n",
    "        list_str = line.rsplit(' ', 1)[0]\n",
    "        # Remove surrounding brackets\n",
    "        list_str = list_str.strip('[').strip(']')\n",
    "        # Split the remaining string by commas to form a list of strings\n",
    "        str_values = list_str.split(',')\n",
    "        # Convert strings to floats\n",
    "        row = [float(value) for value in str_values]\n",
    "        # Append the row to our data list\n",
    "        poff_values.append(row)\n",
    "  \n",
    "poff_values = poff_values[row_index][:len(unique_data)]    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4386e084-a0a8-4d17-b0f4-706c0aff166f",
   "metadata": {},
   "source": [
    "### Standard deviation of r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "810f5d7b-1ad8-4dbe-83a2-1803091fc668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.405034677898422\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define simulation hyperparameters\n",
    "num_points = 50\n",
    "num_simulations = 200\n",
    "a_inv=200.0\n",
    "b_inv=20.0\n",
    "c=20.0\n",
    "sim_time = 0.2\n",
    "num_points2 = 50\n",
    "\n",
    "# Initialize lists to store loss\n",
    "loss_list = []\n",
    "\n",
    "# Generate a range of r values around the optimal value\n",
    "r_list = np.linspace(r - r * 0.8, r * 2, num_points)\n",
    "\n",
    "# Perform simulation for each r value\n",
    "for r_value in r_list:\n",
    "    # Perform Gillespie simulation\n",
    "    mean, var = gillespie_simulation(torch.tensor(poff_values), torch.tensor([r_value]), torch.tensor([g]))\n",
    "    # Calculate loss based on simulation results\n",
    "    loss = loss_function(mean, var)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "# Polynomial fitting\n",
    "degree = 6\n",
    "# Fit a polynomial curve to the loss data\n",
    "coeffs = np.polyfit(r_list, loss_list, degree)\n",
    "poly_func = np.poly1d(coeffs)\n",
    "# Calculate first and second derivatives of the polynomial curve\n",
    "first_derivative = np.polyder(poly_func, 1)\n",
    "second_derivative = np.polyder(poly_func, 2)\n",
    "\n",
    "# Define evaluation points for curvature analysis\n",
    "evaluation_points = np.linspace(r_list[0], r_list[-1], num_points2)\n",
    "\n",
    "# Evaluate curvature at each point\n",
    "curvatures = [second_derivative(point) for point in evaluation_points]\n",
    "\n",
    "# Compute the average curvature\n",
    "average_curvature = np.mean(curvatures)\n",
    "\n",
    "# Compute standard deviation based on average curvature\n",
    "std_r = 1 / np.sqrt(abs(average_curvature))\n",
    "\n",
    "# Print the computed standard deviation\n",
    "print(std_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c30f1-f56a-4755-80b1-2eecbfc33d5a",
   "metadata": {},
   "source": [
    "### Standard deviation of gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f9f8f2d-27ca-4063-86a7-37af13a9b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4088092130724281\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define simulation hyperparameters\n",
    "num_points = 50\n",
    "num_simulation = 200\n",
    "a_inv=200.0\n",
    "b_inv=20.0\n",
    "c=20.0\n",
    "sim_time = 0.2\n",
    "num_points2 = 50\n",
    "\n",
    "# Initialize lists to store loss\n",
    "loss_list = []\n",
    "\n",
    "# Generate a range of g values around the optimal value\n",
    "g_list = np.linspace(g-g*0.8, g*2, num_points)\n",
    "\n",
    "# Perform simulation for each g value\n",
    "for g_value in g_list:\n",
    "    mean, var = gillespie_simulation(torch.tensor(poff_values), torch.tensor([r]), torch.tensor([g_value]))\n",
    "    loss = loss_function(mean, var)\n",
    "    loss_list.append(loss.item())\n",
    "\n",
    "# Polynomial fitting\n",
    "degree = 6\n",
    "# Fit a polynomial curve to the loss data\n",
    "coeffs = np.polyfit(g_list, loss_list, degree)\n",
    "poly_func = np.poly1d(coeffs)\n",
    "# Calculate first and second derivatives of the polynomial curve\n",
    "first_derivative = np.polyder(poly_func, 1)\n",
    "second_derivative = np.polyder(poly_func, 2)\n",
    "\n",
    "# Define evaluation points for curvature analysis\n",
    "evaluation_points = np.linspace(g_list[0], g_list[-1], num_points2)\n",
    "\n",
    "# Evaluate curvature at each point\n",
    "curvatures = [second_derivative(point) for point in evaluation_points]\n",
    "\n",
    "# Compute the average curvature\n",
    "average_curvature = np.mean(curvatures)\n",
    "\n",
    "# Compute standard deviation based on average curvature\n",
    "std_g = 1 / np.sqrt(abs(average_curvature))\n",
    "\n",
    "# Print the computed standard deviation\n",
    "print(std_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5008f9a2-ae17-44c9-abb3-208b438585f1",
   "metadata": {},
   "source": [
    "### Standard deviation of r/gamma using propagation of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cad37c95-eec7-487c-8f2c-44781f1ac3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.012052160263097\n"
     ]
    }
   ],
   "source": [
    "std_r_g = (r/g) * ((std_r/r)**2 + (std_g/g)**2)**0.5\n",
    "print(std_r_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d8b5f-b89a-4570-ade7-13e14e8db38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
